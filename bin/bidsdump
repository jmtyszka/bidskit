#!/usr/bin/env python
# Create a table of key BOLD fMRI parameters for a BIDS dataset
#
# AUTHOR : Mike Tyszka
# PLACE  : Caltech
# DATES  : 2021-05-06 JMT From scratch
#          2024-05-03 JMT Fix handling of missing fields
#          2024-07-11 JMT Expand from just BOLD series to all series types

import os.path as op
import sys
import argparse
import json
import bids
import pandas as pd
import nibabel as nib
from tabulate import tabulate
from glob import glob


def main():

    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Create table of key imaging parameters for a BIDS dataset')
    parser.add_argument('-d', '--dataset', default='.', help='BIDS dataset directory')
    args = parser.parse_args()

    bids_dir = op.realpath(args.dataset)

    print('')
    print('BIDS Simple Parameter Table')
    print('-------------------------')
    print('BIDS dataset directory : {}'.format(bids_dir))

    print('Searching for series metadata (JSON sidecars)')
    json_list = sorted(glob(op.join(bids_dir, 'sub-*', 'ses-*', '*', '*.json')))

    if len(json_list) < 1:
        print('* No metadata found - exiting')
        sys.exit(1)

    meta_list = []
    
    for json_path in json_list:

        json_dir = op.dirname(json_path)
        json_fname = op.basename(json_path)

        # Only process Nifti image data
        nii_fname = json_fname.replace('.json', '.nii.gz')
        nii_path = op.join(json_dir, nii_fname)

        if op.exists(nii_path):

            print('  Processing {}'.format(nii_fname))

            # Load Nifti header
            nii = nib.load(nii_path)
            hdr = nii.header

            # Image dimensions
            dim = hdr['dim']
            vox = hdr['pixdim']

            # Parse BIDS filename
            keys = bids.layout.parse_file_entities(json_path)

            # Load JSON metadata
            with open(json_path, 'r') as fd:
                meta = json.load(fd)

            # Original series number and acquisition time
            ser_no = meta['SeriesNumber']
            acq_time = meta['AcquisitionTime']

            # In-plane GRAPPA factor if present
            if 'ParallelReductionFactorInPlane' in meta:
                r = meta['ParallelReductionFactorInPlane']
            else:
                r = 1

            #  Multiband acceleration factor if present
            if 'MultibandAccelerationFactor' in meta:
                m = meta['MultibandAccelerationFactor']
            else:
                m = 1

            # Handle commonly absent fields
            if not 'session' in keys:
                keys['session'] = '-'
            if not 'task' in keys:
                keys['task'] = '-'
            if not 'run' in keys:
                keys['run'] = 1
            if not 'part' in keys:
                keys['part'] = 'mag'

            # Add to running list
            meta_list.append([
                ser_no,
                acq_time,
                nii_fname,
                keys['subject'],
                keys['session'],
                keys['task'],
                keys['run'],
                keys['part'],
                meta['RepetitionTime'],
                meta['EchoTime'],
                meta['FlipAngle'],
                r, m,
                dim[1], dim[2], dim[3], dim[4],
                vox[1], vox[2], vox[3]
            ])
               
    # Convert list to dataframe and save as CSV
    df = pd.DataFrame(
        meta_list,
        columns=[
            'SeriesNumber',
            'AcquisitionTime',
            'Filename',
            'Subject',
            'Session',
            'Task',
            'Run',
            'Part',
            'TR_secs',
            'TE_secs',
            'FlipAngle_degs',
            'R', 'M',
            'nx', 'ny', 'nz', 'nt',
            'vx_mm', 'vy_mm', 'vz_mm'
        ]
    )

    # Set row index to SeriesNumber
    df.sort_values(by='SeriesNumber', inplace=True)

    csv_fname = op.join(bids_dir, 'bidsdump.csv')
    print('')
    print('Saving BIDS BOLD info to {}'.format(csv_fname))
    df.to_csv(csv_fname, index=False)

    # Pretty print dataframe as a table to stdout
    print('')
    print(tabulate(df, headers='keys', tablefmt='github', stralign='left', numalign='decimal', showindex=False))


if "__main__" in __name__:

    main()
